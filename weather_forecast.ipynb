{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from display import get_cmap\n",
    "\n",
    "vil_cmap,vil_norm,vil_vmin,vil_vmax = get_cmap('vil',encoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['IN_ir069', 'IN_ir107', 'IN_lght', 'IN_vil', 'OUT_vil']>\n",
      "5088\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('data/processed/nowcast_training_000.h5','r') as hf:\n",
    "    print(\"Keys: %s\" % hf.keys())\n",
    "    print(len(hf['IN_vil']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize, Compose, ToTensor\n",
    "class SevirDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, root = '..', type = 'train'):\n",
    "        \n",
    "        DEST_TRAIN_FILE= os.path.join(root,'data/processed/nowcast_training_000.h5')\n",
    "        DEST_TRAIN_META=os.path.join(root, 'data/processed/nowcast_training_000_META.csv')\n",
    "        DEST_TEST_FILE= os.path.join(root, 'data/processed/nowcast_testing_000.h5')\n",
    "        DEST_TEST_META= os.path.join(root, 'data/processed/nowcast_testing_000_META.csv')\n",
    "        self.transform = Compose([ToTensor(),\n",
    "                                    Resize(size=(48,48))])\n",
    "        if type=='train':\n",
    "            self.data_file = DEST_TRAIN_FILE\n",
    "            self.meta_file = DEST_TRAIN_META \n",
    "        else:\n",
    "            self.data_file = DEST_TEST_FILE\n",
    "            self.meta_file = DEST_TEST_META\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "                \n",
    "        with h5py.File(self.data_file,'r') as hf:\n",
    "            input_img_seq = hf['IN_vil'][index].astype(float)\n",
    "            output_img_seq = hf['OUT_vil'][index].astype(float)\n",
    "        input_img_seq = self.transform(input_img_seq)\n",
    "        output_img_seq = self.transform(output_img_seq)\n",
    "        return input_img_seq, output_img_seq\n",
    "    \n",
    "    def __len__(self):\n",
    "        with h5py.File(self.data_file,'r') as hf:\n",
    "            return len(hf['IN_vil'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sevir_dataset = SevirDataset(root='')\n",
    "train_dataloader = data.DataLoader(sevir_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_seq, output_img_seq = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from display import get_cmap\n",
    "\n",
    "vil_cmap,vil_norm,vil_vmin,vil_vmax = get_cmap('vil',encoded=True)\n",
    "\n",
    "fig,axs=plt.subplots(4,4,figsize=(10,5))\n",
    "idx = 0\n",
    "for i in range(0,4):\n",
    "    for j in range(0,4):\n",
    "        if idx < (input_img_seq[0].shape[2]):\n",
    "            axs[i,j].imshow(input_img_seq[0][:,:,idx], cmap=vil_cmap,norm=vil_norm,vmin=vil_vmin,vmax=vil_vmax)\n",
    "            axs[i,j].set_axis_off()\n",
    "            idx+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, frame_size):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        \n",
    "        self.conv2d = nn.Conv2d(in_channels=in_channels+out_channels, out_channels=4*out_channels, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "        self.W_ci = nn.Parameter(torch.Tensor(out_channels, *frame_size)).cuda()\n",
    "        self.W_co = nn.Parameter(torch.Tensor(out_channels, *frame_size)).cuda()\n",
    "        self.W_cf = nn.Parameter(torch.Tensor(out_channels, *frame_size)).cuda()\n",
    "\n",
    "    def forward(self, X, H_previous, C_previous):\n",
    "        conv_output = self.conv2d(torch.cat([X, H_previous], dim=1))\n",
    "        i_conv, f_conv, C_conv, o_conv = torch.chunk(conv_output, chunks=4, dim=1)\n",
    "        input_gate = torch.sigmoid(i_conv + self.W_ci * C_previous )\n",
    "        forget_gate = torch.sigmoid(f_conv + self.W_cf * C_previous )\n",
    "        C = forget_gate*C_previous + input_gate * torch.relu(C_conv)\n",
    "        output_gate = torch.sigmoid(o_conv + self.W_co * C )\n",
    "        H = output_gate * torch.relu(C)\n",
    "\n",
    "        return H, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, frame_size):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.convLSTMCell = ConvLSTMCell(in_channels, out_channels, kernel_size, padding, frame_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_size, _, seq_len, height, width = X.size()\n",
    "        output = torch.zeros(batch_size, self.out_channels, seq_len, height, width).cuda()\n",
    "        H = torch.zeros(batch_size, self.out_channels, height, width).cuda()\n",
    "        C = torch.zeros(batch_size, self.out_channels, height, width).cuda()\n",
    "        for time_step in range(seq_len):\n",
    "            H, C = self.convLSTMCell(X[:,:,time_step,:,:], H, C)\n",
    "            output[:,:,time_step,:,:] = H\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, num_channels, num_kernels, kernel_size, padding, frame_size, num_layers):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.sequential = nn.Sequential()\n",
    "        self.sequential.add_module('convLSTM_1',ConvLSTM(in_channels=num_channels, out_channels=num_kernels, kernel_size=kernel_size, padding=padding, frame_size=frame_size))\n",
    "        self.sequential.add_module('BatchNorm_1',nn.BatchNorm3d(num_features=num_kernels))\n",
    "        for l in range(2, num_layers+1):\n",
    "            self.sequential.add_module(f'convLSTM_{l}',ConvLSTM(in_channels=num_kernels, out_channels=num_kernels, kernel_size=kernel_size, padding=padding, frame_size=frame_size))\n",
    "            self.sequential.add_module(f'BatchNorm_{l}',nn.BatchNorm3d(num_features=num_kernels))\n",
    "        self.conv = nn.Conv2d(in_channels=num_kernels, out_channels=num_channels, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_size, num_channels, seq_len, height, width = X.size()\n",
    "        output = self.sequential(X)\n",
    "        output_list=torch.zeros(batch_size,num_channels,seq_len-1,height,width).cuda()\n",
    "        for time_step in range(seq_len-1):\n",
    "            output_list[:,:,time_step,:,:] = nn.Sigmoid()(self.conv(output[:,:,time_step,:,:]))\n",
    "        return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (sequential): Sequential(\n",
       "    (convLSTM_1): ConvLSTM(\n",
       "      (convLSTMCell): ConvLSTMCell(\n",
       "        (conv2d): Conv2d(49, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (BatchNorm_1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convLSTM_2): ConvLSTM(\n",
       "      (convLSTMCell): ConvLSTMCell(\n",
       "        (conv2d): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (BatchNorm_2): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convLSTM_3): ConvLSTM(\n",
       "      (convLSTMCell): ConvLSTMCell(\n",
       "        (conv2d): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (BatchNorm_3): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv): Conv2d(48, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_2 = Seq2Seq(num_channels=1, num_kernels=48, kernel_size=(3,3), padding=(1,1), frame_size=(48,48), num_layers=3)\n",
    "net_2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417745"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(\n",
    "\tparam.numel() for param in net_2.parameters()\n",
    ")\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "optimizer = optim.Adam(net_2.parameters(), lr=0.001)\n",
    "\n",
    "# define loss\n",
    "L1Loss = nn.L1Loss()\n",
    "# SmoothL1Loss = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 0.9175 sec.\n",
      "iter 0 || Loss: 10.8049 \n",
      "Timer: 0.9532 sec.\n",
      "iter 0 || Loss: 22.1372 \n",
      "Timer: 1.0492 sec.\n",
      "iter 0 || Loss: 39.8024 \n",
      "Timer: 0.8452 sec.\n",
      "iter 0 || Loss: 65.6912 \n",
      "Timer: 0.9656 sec.\n",
      "iter 0 || Loss: 91.0598 \n",
      "Timer: 0.9356 sec.\n",
      "iter 0 || Loss: 102.3130 \n",
      "Timer: 1.0616 sec.\n",
      "iter 0 || Loss: 120.4918 \n",
      "Timer: 0.9170 sec.\n",
      "iter 0 || Loss: 138.7527 \n",
      "Timer: 0.8519 sec.\n",
      "iter 0 || Loss: 151.6415 \n",
      "Timer: 0.9953 sec.\n",
      "iter 0 || Loss: 171.8419 \n",
      "Timer: 0.8957 sec.\n",
      "iter 0 || Loss: 203.0634 \n",
      "Timer: 0.9117 sec.\n",
      "iter 0 || Loss: 220.1098 \n",
      "Timer: 0.8726 sec.\n",
      "iter 0 || Loss: 234.0349 \n",
      "Timer: 1.0412 sec.\n",
      "iter 0 || Loss: 252.6788 \n",
      "Timer: 0.7669 sec.\n",
      "iter 0 || Loss: 265.4454 \n",
      "Timer: 0.9529 sec.\n",
      "iter 0 || Loss: 286.6184 \n",
      "Timer: 0.9854 sec.\n",
      "iter 0 || Loss: 305.8898 \n",
      "Timer: 1.0114 sec.\n",
      "iter 0 || Loss: 323.1293 \n",
      "Timer: 0.8817 sec.\n",
      "iter 0 || Loss: 335.4227 \n",
      "Timer: 1.0432 sec.\n",
      "iter 0 || Loss: 342.7151 \n",
      "Timer: 0.9056 sec.\n",
      "iter 0 || Loss: 366.7134 \n",
      "Timer: 0.8627 sec.\n",
      "iter 0 || Loss: 375.4913 \n",
      "Timer: 0.8675 sec.\n",
      "iter 0 || Loss: 398.4692 \n",
      "Timer: 0.8711 sec.\n",
      "iter 0 || Loss: 407.4824 \n",
      "Timer: 0.9135 sec.\n",
      "iter 0 || Loss: 431.4338 \n",
      "Timer: 0.9784 sec.\n",
      "iter 0 || Loss: 452.3221 \n",
      "Timer: 1.0740 sec.\n",
      "iter 0 || Loss: 472.1687 \n",
      "Timer: 0.9824 sec.\n",
      "iter 0 || Loss: 488.2964 \n",
      "Timer: 0.9844 sec.\n",
      "iter 0 || Loss: 511.3052 \n",
      "Timer: 0.9320 sec.\n",
      "iter 0 || Loss: 531.6237 \n",
      "Timer: 1.0163 sec.\n",
      "iter 0 || Loss: 548.9933 \n",
      "Timer: 0.9254 sec.\n",
      "iter 0 || Loss: 566.0593 \n",
      "Timer: 0.8846 sec.\n",
      "iter 0 || Loss: 590.0309 \n",
      "Timer: 0.8877 sec.\n",
      "iter 0 || Loss: 604.6576 \n",
      "Timer: 0.8834 sec.\n",
      "iter 0 || Loss: 621.2027 \n",
      "Timer: 0.9804 sec.\n",
      "iter 0 || Loss: 633.4899 \n",
      "Timer: 1.0413 sec.\n",
      "iter 0 || Loss: 656.9785 \n",
      "Timer: 0.8757 sec.\n",
      "iter 0 || Loss: 676.1625 \n",
      "Timer: 0.9754 sec.\n",
      "iter 0 || Loss: 704.4935 \n",
      "Timer: 0.9329 sec.\n",
      "iter 0 || Loss: 717.0972 \n",
      "Timer: 1.0106 sec.\n",
      "iter 0 || Loss: 730.0152 \n",
      "Timer: 0.9604 sec.\n",
      "iter 0 || Loss: 750.8986 \n",
      "Timer: 0.8158 sec.\n",
      "iter 0 || Loss: 760.0786 \n",
      "Timer: 1.0402 sec.\n",
      "iter 0 || Loss: 771.1022 \n",
      "Timer: 0.9324 sec.\n",
      "iter 0 || Loss: 800.6566 \n",
      "Timer: 1.0625 sec.\n",
      "iter 0 || Loss: 820.1047 \n",
      "Timer: 0.9438 sec.\n",
      "iter 0 || Loss: 832.4412 \n",
      "Timer: 0.8916 sec.\n",
      "iter 0 || Loss: 872.9673 \n",
      "Timer: 0.8758 sec.\n",
      "iter 0 || Loss: 893.7837 \n",
      "Timer: 0.7588 sec.\n",
      "iter 0 || Loss: 904.7306 \n",
      "Timer: 0.9644 sec.\n",
      "iter 0 || Loss: 930.9211 \n",
      "Timer: 0.9469 sec.\n",
      "iter 0 || Loss: 957.0093 \n",
      "Timer: 1.0109 sec.\n",
      "iter 0 || Loss: 978.2105 \n",
      "Timer: 0.9619 sec.\n",
      "iter 0 || Loss: 1011.1372 \n",
      "Timer: 0.8986 sec.\n",
      "iter 0 || Loss: 1046.4652 \n",
      "Timer: 1.0143 sec.\n",
      "iter 0 || Loss: 1066.4001 \n",
      "Timer: 1.0542 sec.\n",
      "iter 0 || Loss: 1089.3020 \n",
      "Timer: 0.7171 sec.\n",
      "iter 0 || Loss: 1110.0484 \n",
      "Timer: 1.0741 sec.\n",
      "iter 0 || Loss: 1134.2074 \n",
      "Timer: 0.8547 sec.\n",
      "iter 0 || Loss: 1149.5888 \n",
      "Timer: 0.9731 sec.\n",
      "iter 0 || Loss: 1170.9660 \n",
      "Timer: 0.7349 sec.\n",
      "iter 0 || Loss: 1184.0930 \n",
      "Timer: 0.8907 sec.\n",
      "iter 0 || Loss: 1213.3376 \n",
      "Timer: 0.9106 sec.\n",
      "iter 0 || Loss: 1230.2860 \n",
      "Timer: 0.9963 sec.\n",
      "iter 0 || Loss: 1257.4435 \n",
      "Timer: 1.0320 sec.\n",
      "iter 0 || Loss: 1283.6639 \n",
      "Timer: 0.9444 sec.\n",
      "iter 0 || Loss: 1297.0072 \n",
      "Timer: 0.9583 sec.\n",
      "iter 0 || Loss: 1305.8241 \n",
      "Timer: 0.9007 sec.\n",
      "iter 0 || Loss: 1324.0161 \n",
      "Timer: 0.9978 sec.\n",
      "iter 0 || Loss: 1346.7354 \n",
      "Timer: 0.9057 sec.\n",
      "iter 0 || Loss: 1355.6505 \n",
      "Timer: 0.9583 sec.\n",
      "iter 0 || Loss: 1372.2860 \n",
      "Timer: 0.9776 sec.\n",
      "iter 0 || Loss: 1384.7876 \n",
      "Timer: 0.9244 sec.\n",
      "iter 0 || Loss: 1403.0102 \n",
      "Timer: 1.0193 sec.\n",
      "iter 0 || Loss: 1416.7730 \n",
      "Timer: 0.7879 sec.\n",
      "iter 0 || Loss: 1436.7649 \n",
      "Timer: 0.7091 sec.\n",
      "iter 0 || Loss: 1458.3637 \n",
      "Timer: 1.0566 sec.\n",
      "iter 0 || Loss: 1500.6641 \n",
      "Timer: 0.7231 sec.\n",
      "iter 0 || Loss: 1509.6235 \n",
      "Timer: 0.8864 sec.\n",
      "iter 0 || Loss: 1522.6731 \n",
      "Timer: 0.9114 sec.\n",
      "iter 0 || Loss: 1548.4217 \n",
      "Timer: 0.7899 sec.\n",
      "iter 0 || Loss: 1562.3516 \n",
      "Timer: 0.9622 sec.\n",
      "iter 0 || Loss: 1578.5349 \n",
      "Timer: 0.8719 sec.\n",
      "iter 0 || Loss: 1598.8871 \n",
      "Timer: 0.9279 sec.\n",
      "iter 0 || Loss: 1614.9338 \n",
      "Timer: 0.9946 sec.\n",
      "iter 0 || Loss: 1642.7667 \n",
      "Timer: 1.0215 sec.\n",
      "iter 0 || Loss: 1659.8936 \n",
      "Timer: 0.8931 sec.\n",
      "iter 0 || Loss: 1668.9114 \n",
      "Timer: 0.8877 sec.\n",
      "iter 0 || Loss: 1685.1426 \n",
      "Timer: 0.9205 sec.\n",
      "iter 0 || Loss: 1701.2087 \n",
      "Timer: 0.8419 sec.\n",
      "iter 0 || Loss: 1726.6006 \n",
      "Timer: 0.9734 sec.\n",
      "iter 0 || Loss: 1739.0082 \n",
      "Timer: 1.0018 sec.\n",
      "iter 0 || Loss: 1751.7242 \n",
      "Timer: 0.8757 sec.\n",
      "iter 0 || Loss: 1783.4674 \n",
      "Timer: 0.9155 sec.\n",
      "iter 0 || Loss: 1799.6417 \n",
      "Timer: 1.0342 sec.\n",
      "iter 0 || Loss: 1814.0318 \n",
      "Timer: 0.9475 sec.\n",
      "iter 0 || Loss: 1838.9028 \n",
      "Timer: 0.8836 sec.\n",
      "iter 0 || Loss: 1855.4775 \n",
      "Timer: 0.9264 sec.\n",
      "iter 0 || Loss: 1875.8747 \n",
      "Timer: 0.9245 sec.\n",
      "iter 0 || Loss: 1892.2570 \n",
      "Timer: 0.7491 sec.\n",
      "iter 0 || Loss: 1909.7742 \n",
      "Timer: 0.9663 sec.\n",
      "iter 0 || Loss: 1923.4598 \n",
      "Timer: 0.9564 sec.\n",
      "iter 0 || Loss: 1948.0644 \n",
      "Timer: 0.9923 sec.\n",
      "iter 0 || Loss: 1973.1625 \n",
      "Timer: 0.8457 sec.\n",
      "iter 0 || Loss: 1983.0986 \n",
      "Timer: 0.9026 sec.\n",
      "iter 0 || Loss: 2000.8519 \n",
      "Timer: 0.9970 sec.\n",
      "iter 0 || Loss: 2014.5951 \n",
      "Timer: 1.0038 sec.\n",
      "iter 0 || Loss: 2034.3946 \n",
      "Timer: 0.9058 sec.\n",
      "iter 0 || Loss: 2051.6623 \n",
      "Timer: 0.9335 sec.\n",
      "iter 0 || Loss: 2062.8659 \n",
      "Timer: 0.9181 sec.\n",
      "iter 0 || Loss: 2080.7679 \n",
      "Timer: 0.8887 sec.\n",
      "iter 0 || Loss: 2099.5018 \n",
      "Timer: 1.0448 sec.\n",
      "iter 0 || Loss: 2111.6748 \n",
      "Timer: 0.9714 sec.\n",
      "iter 0 || Loss: 2132.1895 \n",
      "Timer: 0.8896 sec.\n",
      "iter 0 || Loss: 2148.4735 \n",
      "Timer: 0.9887 sec.\n",
      "iter 0 || Loss: 2170.7779 \n",
      "Timer: 0.9245 sec.\n",
      "iter 0 || Loss: 2190.0509 \n",
      "Timer: 0.8530 sec.\n",
      "iter 0 || Loss: 2208.4213 \n",
      "Timer: 0.8487 sec.\n",
      "iter 0 || Loss: 2230.1093 \n",
      "Timer: 0.9246 sec.\n",
      "iter 0 || Loss: 2248.8241 \n",
      "Timer: 0.9155 sec.\n",
      "iter 0 || Loss: 2270.8602 \n",
      "Timer: 1.0422 sec.\n",
      "iter 0 || Loss: 2286.4383 \n",
      "Timer: 0.8677 sec.\n",
      "iter 0 || Loss: 2306.6020 \n",
      "Timer: 0.8228 sec.\n",
      "iter 0 || Loss: 2320.1579 \n",
      "Timer: 0.9687 sec.\n",
      "iter 0 || Loss: 2340.8192 \n",
      "Timer: 0.9778 sec.\n",
      "iter 0 || Loss: 2359.3157 \n",
      "Timer: 1.0446 sec.\n",
      "iter 0 || Loss: 2377.8737 \n",
      "Timer: 0.8557 sec.\n",
      "iter 0 || Loss: 2400.4128 \n",
      "Timer: 0.8816 sec.\n",
      "iter 0 || Loss: 2415.5082 \n",
      "Timer: 0.8388 sec.\n",
      "iter 0 || Loss: 2428.2989 \n",
      "Timer: 1.0251 sec.\n",
      "iter 0 || Loss: 2444.8438 \n",
      "Timer: 0.9036 sec.\n",
      "iter 0 || Loss: 2459.4246 \n",
      "Timer: 0.9486 sec.\n",
      "iter 0 || Loss: 2495.8854 \n",
      "Timer: 0.8537 sec.\n",
      "iter 0 || Loss: 2521.4592 \n",
      "Timer: 0.8829 sec.\n",
      "iter 0 || Loss: 2539.5280 \n",
      "Timer: 0.9006 sec.\n",
      "iter 0 || Loss: 2554.8593 \n",
      "Timer: 0.8876 sec.\n",
      "iter 0 || Loss: 2578.3783 \n",
      "Timer: 0.8108 sec.\n",
      "iter 0 || Loss: 2600.6612 \n",
      "Timer: 0.7420 sec.\n",
      "iter 0 || Loss: 2620.9472 \n",
      "Timer: 0.8188 sec.\n",
      "iter 0 || Loss: 2645.4833 \n",
      "Timer: 0.9654 sec.\n",
      "iter 0 || Loss: 2662.1655 \n",
      "Timer: 0.9973 sec.\n",
      "iter 0 || Loss: 2673.5364 \n",
      "Timer: 0.9732 sec.\n",
      "iter 0 || Loss: 2689.0287 \n",
      "Timer: 0.9214 sec.\n",
      "iter 0 || Loss: 2725.6863 \n",
      "Timer: 0.9554 sec.\n",
      "iter 0 || Loss: 2741.4687 \n",
      "Timer: 0.9889 sec.\n",
      "iter 0 || Loss: 2756.1433 \n",
      "Timer: 0.9271 sec.\n",
      "iter 0 || Loss: 2783.9985 \n",
      "Timer: 0.9894 sec.\n",
      "iter 0 || Loss: 2804.8963 \n",
      "Timer: 0.9614 sec.\n",
      "iter 0 || Loss: 2819.0214 \n",
      "Timer: 1.0333 sec.\n",
      "iter 0 || Loss: 2843.8039 \n",
      "Timer: 1.0646 sec.\n",
      "iter 0 || Loss: 2867.2808 \n",
      "Timer: 0.9705 sec.\n",
      "iter 0 || Loss: 2888.0568 \n",
      "Timer: 0.8976 sec.\n",
      "iter 0 || Loss: 2904.3154 \n",
      "Timer: 0.7239 sec.\n",
      "iter 0 || Loss: 2923.9449 \n",
      "Timer: 0.9340 sec.\n",
      "iter 0 || Loss: 2939.6006 \n",
      "Timer: 0.9486 sec.\n",
      "iter 0 || Loss: 2952.1820 \n",
      "Timer: 0.9505 sec.\n",
      "iter 0 || Loss: 2967.1843 \n",
      "Timer: 1.0286 sec.\n",
      "iter 0 || Loss: 2977.9435 \n",
      "Timer: 0.9988 sec.\n",
      "iter 0 || Loss: 2995.7888 \n",
      "Timer: 1.0676 sec.\n",
      "iter 0 || Loss: 3015.5900 \n",
      "Timer: 0.7483 sec.\n",
      "iter 0 || Loss: 3047.2461 \n",
      "Timer: 0.8128 sec.\n",
      "iter 0 || Loss: 3068.5865 \n",
      "Timer: 1.0221 sec.\n",
      "iter 0 || Loss: 3091.0760 \n",
      "Timer: 0.9564 sec.\n",
      "iter 0 || Loss: 3106.6556 \n",
      "Timer: 0.8866 sec.\n",
      "iter 0 || Loss: 3118.5840 \n",
      "Timer: 1.0023 sec.\n",
      "iter 0 || Loss: 3143.2977 \n",
      "Timer: 0.8650 sec.\n",
      "iter 0 || Loss: 3159.7386 \n",
      "Timer: 0.9784 sec.\n",
      "iter 0 || Loss: 3181.1470 \n",
      "Timer: 1.0123 sec.\n",
      "iter 0 || Loss: 3195.9673 \n",
      "Timer: 0.7404 sec.\n",
      "iter 0 || Loss: 3207.1361 \n",
      "Timer: 1.0113 sec.\n",
      "iter 0 || Loss: 3218.4988 \n",
      "Timer: 0.9191 sec.\n",
      "iter 0 || Loss: 3237.1124 \n",
      "Timer: 0.8994 sec.\n",
      "iter 0 || Loss: 3269.4242 \n",
      "Timer: 0.9564 sec.\n",
      "iter 0 || Loss: 3283.8468 \n",
      "Timer: 0.9744 sec.\n",
      "iter 0 || Loss: 3309.6134 \n",
      "Timer: 0.9150 sec.\n",
      "iter 0 || Loss: 3331.4723 \n",
      "Timer: 1.0392 sec.\n",
      "iter 0 || Loss: 3358.0480 \n",
      "Timer: 0.9269 sec.\n",
      "iter 0 || Loss: 3373.3677 \n",
      "Timer: 0.8906 sec.\n",
      "iter 0 || Loss: 3392.3619 \n",
      "Timer: 1.0542 sec.\n",
      "iter 0 || Loss: 3422.4969 \n",
      "Timer: 0.8786 sec.\n",
      "iter 0 || Loss: 3435.3060 \n",
      "Timer: 1.0402 sec.\n",
      "iter 0 || Loss: 3462.4425 \n",
      "Timer: 0.8996 sec.\n",
      "iter 0 || Loss: 3470.0911 \n",
      "Timer: 0.8587 sec.\n",
      "iter 0 || Loss: 3481.1073 \n",
      "Timer: 1.0293 sec.\n",
      "iter 0 || Loss: 3502.1876 \n",
      "Timer: 1.0582 sec.\n",
      "iter 0 || Loss: 3518.5258 \n",
      "Timer: 0.8966 sec.\n",
      "iter 0 || Loss: 3542.2260 \n",
      "Timer: 0.9289 sec.\n",
      "iter 0 || Loss: 3562.8751 \n",
      "Timer: 1.0114 sec.\n",
      "iter 0 || Loss: 3581.5079 \n",
      "Timer: 1.0804 sec.\n",
      "iter 0 || Loss: 3603.7314 \n",
      "Timer: 1.0612 sec.\n",
      "iter 0 || Loss: 3646.2254 \n",
      "Timer: 0.8657 sec.\n",
      "iter 0 || Loss: 3676.7775 \n",
      "Timer: 1.0372 sec.\n",
      "iter 0 || Loss: 3699.9983 \n",
      "Timer: 0.9734 sec.\n",
      "iter 0 || Loss: 3721.7364 \n",
      "Timer: 1.0268 sec.\n",
      "iter 0 || Loss: 3737.0581 \n",
      "Timer: 0.8943 sec.\n",
      "iter 0 || Loss: 3756.5653 \n",
      "Timer: 1.0322 sec.\n",
      "iter 0 || Loss: 3769.1108 \n",
      "Timer: 0.9335 sec.\n",
      "iter 0 || Loss: 3784.3654 \n",
      "Timer: 0.9065 sec.\n",
      "iter 0 || Loss: 3811.2460 \n",
      "Timer: 1.0455 sec.\n",
      "iter 0 || Loss: 3827.7665 \n",
      "Timer: 0.8964 sec.\n",
      "iter 0 || Loss: 3853.0642 \n",
      "Timer: 0.9574 sec.\n",
      "iter 0 || Loss: 3872.8376 \n",
      "Timer: 1.0701 sec.\n",
      "iter 0 || Loss: 3898.1975 \n",
      "Timer: 1.0684 sec.\n",
      "iter 0 || Loss: 3916.4092 \n",
      "Timer: 0.9963 sec.\n",
      "iter 0 || Loss: 3937.1768 \n",
      "Timer: 0.9814 sec.\n",
      "iter 0 || Loss: 3948.6782 \n",
      "Timer: 1.0000 sec.\n",
      "iter 0 || Loss: 3955.2027 \n",
      "Timer: 1.0253 sec.\n",
      "iter 0 || Loss: 3980.0335 \n",
      "Timer: 0.9414 sec.\n",
      "iter 0 || Loss: 3993.5367 \n",
      "Timer: 0.9664 sec.\n",
      "iter 0 || Loss: 4005.8524 \n",
      "Timer: 0.9554 sec.\n",
      "iter 0 || Loss: 4032.2598 \n",
      "Timer: 0.9315 sec.\n",
      "iter 0 || Loss: 4054.5546 \n",
      "Timer: 0.9737 sec.\n",
      "iter 0 || Loss: 4082.3197 \n",
      "Timer: 0.8710 sec.\n",
      "iter 0 || Loss: 4106.7272 \n",
      "Timer: 0.9048 sec.\n",
      "iter 0 || Loss: 4126.1357 \n",
      "Timer: 1.0801 sec.\n",
      "iter 0 || Loss: 4141.6118 \n",
      "Timer: 0.9262 sec.\n",
      "iter 0 || Loss: 4159.0670 \n",
      "Timer: 0.9534 sec.\n",
      "iter 0 || Loss: 4167.5832 \n",
      "Timer: 1.0090 sec.\n",
      "iter 0 || Loss: 4188.9536 \n",
      "Timer: 1.0661 sec.\n",
      "iter 0 || Loss: 4202.1979 \n",
      "Timer: 0.9814 sec.\n",
      "iter 0 || Loss: 4223.2918 \n",
      "Timer: 0.9185 sec.\n",
      "iter 0 || Loss: 4243.8121 \n",
      "Timer: 1.0894 sec.\n",
      "iter 0 || Loss: 4270.9337 \n",
      "Timer: 0.8764 sec.\n",
      "iter 0 || Loss: 4292.3666 \n",
      "Timer: 1.0299 sec.\n",
      "iter 0 || Loss: 4311.5287 \n",
      "Timer: 0.8403 sec.\n",
      "iter 0 || Loss: 4317.3334 \n",
      "Timer: 0.9465 sec.\n",
      "iter 0 || Loss: 4341.1323 \n",
      "Timer: 1.0093 sec.\n",
      "iter 0 || Loss: 4360.4662 \n",
      "Timer: 0.9634 sec.\n",
      "iter 0 || Loss: 4379.6705 \n",
      "Timer: 0.9792 sec.\n",
      "iter 0 || Loss: 4394.8201 \n",
      "Timer: 1.0073 sec.\n",
      "iter 0 || Loss: 4417.9859 \n",
      "Timer: 1.0365 sec.\n",
      "iter 0 || Loss: 4433.4368 \n",
      "Timer: 0.9893 sec.\n",
      "iter 0 || Loss: 4448.3709 \n",
      "Timer: 0.8786 sec.\n",
      "iter 0 || Loss: 4462.6976 \n",
      "Timer: 0.9315 sec.\n",
      "iter 0 || Loss: 4477.8885 \n",
      "Timer: 0.8408 sec.\n",
      "iter 0 || Loss: 4492.6547 \n",
      "Timer: 0.9146 sec.\n",
      "iter 0 || Loss: 4508.3793 \n",
      "Timer: 0.9205 sec.\n",
      "iter 0 || Loss: 4518.3460 \n",
      "Timer: 0.8906 sec.\n",
      "iter 0 || Loss: 4531.2854 \n",
      "Timer: 0.9345 sec.\n",
      "iter 0 || Loss: 4547.8077 \n",
      "Timer: 1.0057 sec.\n",
      "iter 0 || Loss: 4570.2011 \n",
      "Timer: 0.9179 sec.\n",
      "iter 0 || Loss: 4594.4865 \n",
      "Timer: 0.7261 sec.\n",
      "iter 0 || Loss: 4624.2139 \n",
      "Timer: 0.9719 sec.\n",
      "iter 0 || Loss: 4648.2958 \n",
      "Timer: 0.7709 sec.\n",
      "iter 0 || Loss: 4670.5885 \n",
      "Timer: 0.8288 sec.\n",
      "iter 0 || Loss: 4691.8991 \n",
      "Timer: 0.9455 sec.\n",
      "iter 0 || Loss: 4706.9075 \n",
      "Timer: 0.9530 sec.\n",
      "iter 0 || Loss: 4723.1551 \n",
      "Timer: 0.8975 sec.\n",
      "iter 0 || Loss: 4731.6213 \n",
      "Timer: 0.9616 sec.\n",
      "iter 0 || Loss: 4745.6697 \n",
      "Timer: 0.8557 sec.\n",
      "iter 0 || Loss: 4779.5987 \n",
      "Timer: 1.0651 sec.\n",
      "iter 0 || Loss: 4793.6582 \n",
      "Timer: 0.8527 sec.\n",
      "iter 0 || Loss: 4826.7166 \n",
      "Timer: 0.8946 sec.\n",
      "iter 0 || Loss: 4861.0314 \n",
      "Timer: 0.7201 sec.\n",
      "iter 0 || Loss: 4879.7671 \n",
      "Timer: 0.9202 sec.\n",
      "iter 0 || Loss: 4900.3150 \n",
      "Timer: 0.8610 sec.\n",
      "iter 0 || Loss: 4922.8049 \n",
      "Timer: 0.9314 sec.\n",
      "iter 0 || Loss: 4933.3542 \n",
      "Timer: 0.8732 sec.\n",
      "iter 0 || Loss: 4955.5023 \n",
      "Timer: 0.9363 sec.\n",
      "iter 0 || Loss: 4971.5638 \n",
      "Timer: 0.8788 sec.\n",
      "iter 0 || Loss: 4989.0975 \n",
      "Timer: 0.8448 sec.\n",
      "iter 0 || Loss: 5001.7571 \n",
      "Timer: 0.9634 sec.\n",
      "iter 0 || Loss: 5010.4309 \n",
      "Timer: 0.8684 sec.\n",
      "iter 0 || Loss: 5032.0798 \n",
      "Timer: 0.9677 sec.\n",
      "iter 0 || Loss: 5066.2758 \n",
      "Timer: 1.0116 sec.\n",
      "iter 0 || Loss: 5089.6011 \n",
      "Timer: 0.9505 sec.\n",
      "iter 0 || Loss: 5103.4180 \n",
      "Timer: 0.9165 sec.\n",
      "iter 0 || Loss: 5133.3708 \n",
      "Timer: 0.8507 sec.\n",
      "iter 0 || Loss: 5146.5248 \n",
      "Timer: 0.9026 sec.\n",
      "iter 0 || Loss: 5171.1300 \n",
      "Timer: 0.8138 sec.\n",
      "iter 0 || Loss: 5180.2569 \n",
      "Timer: 0.9794 sec.\n",
      "iter 0 || Loss: 5196.6265 \n",
      "Timer: 0.8273 sec.\n",
      "iter 0 || Loss: 5225.2709 \n",
      "Timer: 0.9165 sec.\n",
      "iter 0 || Loss: 5244.4525 \n",
      "Timer: 0.9006 sec.\n",
      "iter 0 || Loss: 5258.9598 \n",
      "Timer: 0.9338 sec.\n",
      "iter 0 || Loss: 5280.7934 \n",
      "Timer: 0.8545 sec.\n",
      "iter 0 || Loss: 5299.3448 \n",
      "Timer: 0.8917 sec.\n",
      "iter 0 || Loss: 5311.5983 \n",
      "Timer: 0.9959 sec.\n",
      "iter 0 || Loss: 5327.5271 \n",
      "Timer: 0.9042 sec.\n",
      "iter 0 || Loss: 5347.7053 \n",
      "Timer: 0.7719 sec.\n",
      "iter 0 || Loss: 5360.5242 \n",
      "Timer: 0.9764 sec.\n",
      "iter 0 || Loss: 5383.2483 \n",
      "Timer: 1.0911 sec.\n",
      "iter 0 || Loss: 5411.1161 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34880\\295222230.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL1Loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_img_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADASDevelopment\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADASDevelopment\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.\n",
    "    for input_data in train_dataloader:\n",
    "        input_img_seq, output_img_seq = input_data\n",
    "\n",
    "        input_img_seq = input_img_seq.type(torch.cuda.FloatTensor).unsqueeze(1)\n",
    "        output_img_seq = output_img_seq.type(torch.cuda.FloatTensor)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t0 = time.time()\n",
    "        output = net_2(input_img_seq)\n",
    "        loss = L1Loss(output.squeeze(1)[:,-1,:,:],output_img_seq[:,-1,:,:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time.time()\n",
    "        running_loss += loss.item()\n",
    "        print('Timer: %.4f sec.' % (t1 - t0))\n",
    "        print('iter ' + repr(epoch) + ' || Loss: %.4f ' % \\\n",
    "                (running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net_2,'ConvLSTM_12_2_23.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 12, 48, 48])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAEeCAYAAADRiP/HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEtklEQVR4nO3cIXLEMBAAwSh179Nj9UEFHDIxyACd67qpyJKtqQX22Hv/AAD/93t6AAB4OjEFgEhMASASUwCIxBQAIjEFgOh19zjn/KrvZtZa4/QMfDY7AVd24s1lCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJANPbep2cAgEdzmQJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAESvu8c551f9uHetNU7PwGezE3BlJ95cpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGPvfXoGAHg0lykARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkD0unucc37Vj3vXWuP0DHw2OwFXduLNZQoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQDT23qdnAIBHc5kCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEr7vHOedX/bh3rTVOz8BnsxNwZSfeXKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERj7316BgB4NJcpAERiCgCRmAJAJKYAEIkpAERiCgDRHxw/QTGSA6KoAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x360 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axs=plt.subplots(4,3,figsize=(10,5))\n",
    "plot_output = output.squeeze(1).cpu().detach().numpy()\n",
    "idx = 0\n",
    "for i in range(0,4):\n",
    "    for j in range(0,3):\n",
    "        if idx < (12):\n",
    "            axs[i,j].imshow(plot_output[0][idx,:,:], cmap=vil_cmap,norm=vil_norm,vmin=vil_vmin,vmax=vil_vmax)\n",
    "            axs[i,j].set_axis_off()\n",
    "            idx+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sevir_test_dataset = SevirDataset(root='',type='test')\n",
    "test_dataloader = data.DataLoader(sevir_test_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_seq, output_img_seq = next(iter(test_dataloader))\n",
    "net = torch.load('ConvLSTM_12_2_23.pth')\n",
    "input_img_seq = input_img_seq.type(torch.cuda.FloatTensor).unsqueeze(1)\n",
    "output = net_2(input_img_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAEeCAYAAADRiP/HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEtklEQVR4nO3cIXLEMBAAwSh179Nj9UEFHDIxyACd67qpyJKtqQX22Hv/AAD/93t6AAB4OjEFgEhMASASUwCIxBQAIjEFgOh19zjn/KrvZtZa4/QMfDY7AVd24s1lCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJANPbep2cAgEdzmQJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAESvu8c551f9uHetNU7PwGezE3BlJ95cpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGPvfXoGAHg0lykARGIKAJGYAkAkpgAQiSkARGIKAJGYAkAkpgAQiSkARGIKAJGYAkD0unucc37Vj3vXWuP0DHw2OwFXduLNZQoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQDT23qdnAIBHc5kCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEYgoAkZgCQCSmABCJKQBEr7vHOedX/bh3rTVOz8BnsxNwZSfeXKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERiCgCRmAJAJKYAEIkpAERj7316BgB4NJcpAERiCgCRmAJAJKYAEIkpAERiCgDRHxw/QTGSA6KoAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x360 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axs=plt.subplots(4,3,figsize=(10,5))\n",
    "plot_output = output.squeeze(1).cpu().detach().numpy()\n",
    "idx = 0\n",
    "for i in range(0,4):\n",
    "    for j in range(0,3):\n",
    "        if idx < (12):\n",
    "            axs[i,j].imshow(plot_output[0][idx,:,:], cmap=vil_cmap,norm=vil_norm,vmin=vil_vmin,vmax=vil_vmax)\n",
    "            axs[i,j].set_axis_off()\n",
    "            idx+=1\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
